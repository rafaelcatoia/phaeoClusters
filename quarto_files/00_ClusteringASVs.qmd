---
title: "Clustering ASVs"
format: 
  html:
    fig-width: 12
    fig-height: 8
    fig-align: center
    echo: true
    code-fold: true
    fig-dpi: 100
    warning: false
    message: false
    page-layout: full
    embed-resources: true
---

::: panel-tabset
# Data Handling

```{r}
library(dplyr) ; library(tidyr) ; library(ggplot2) 
library(doParallel) ; library(foreach) ; library(doSNOW)

root <- rprojroot::has_file(".git/index")
datadir = root$find_file("data")
funsdir = root$find_file("functions")
savingdir = root$find_file("saved_files")

datapath = root$find_file(paste0(datadir,'/','grump.phaeocystis_asv_long.csv'))
files_vec <- list.files(funsdir)
currentwd <- getwd()

for( i in 1:length(files_vec)){
  source(root$find_file(paste0(funsdir,'/',files_vec[i])))
}

getwd()
funcitons_parallel = c("clusterize_ward_pam",
                       "eval_adist_clustering",
                       "inducedDist",
                       "summarise_adist_clustering",
                       "tidy_grump")

dframe = data.table::fread(input = datapath)
dframe = tidy_grump(Dframe = dframe)
```

# splitting inducer distance matrix

The idea is to create a 'custom' distance matrix, to induce the grouppings.

-   $c_1$ is within the same species - but no unassigned
-   $c_2$ is between assigned species
-   $c_3$ is between species and unassigned
-   $c_4$ is within unassigned and unassigned

![](InduceddistMatrix.png){width="25%" fig-align="center"}

For this document we will use only the following configuration:

$c_1=1$, $c_2=1000$, $c_3=10$ , $c_4=10$

A priori, the 'probability\` of unassigned ASVs to agglomerate between themselves is the same as if it was to agglomerate with other species. Large $c_2$ makes it harder for known species ASVs to group between themselves.

```{r}
inducedDist_ = inducedDist(
  dFrame = dframe$dframe,
  c1 = 1,c2=1000,c3=10,c4=10,
  compMatrix = dframe$ASV_composition)

#inducedDist$myDist_checking
```

# Metrics

::: panel-tabset
## Proposed

$$ S = \frac{numerator}{denominator} $$

Where:

$$ numerator = \frac{1}{k} \left( \sum_{j=1}^{k}  \left[ \frac{1}{n_j}\sum_{i}^{n_j} d(x_i-\bar x^{(j)} ) \right]  \right) $$

The mean average distance within clusters (each observation and the medoid of the cluster)

$$ denominator = \frac{1}{\binom{k}{2}} \sum_{i \neq j }  d( \bar x^{(i)}-\bar x^{(j)} ) $$

The average distance between clusters (each cluster is represented by it's medoid)

## Permanova

$$ S = \frac{numerator}{denominator} $$

Where:

$$ SS_T = \frac{1}{N} \sum_{i=1}^{N-1}  \sum_{j=i+1}^{N-1} d^2_{ij} $$

Being $d^2_{ij}$ is the squared distance between objects $i$ and $j$.

$$ SS_W = \frac{1}{n} \sum_{i=1}^{N-1}  \sum_{j=i+1}^{N-1} d^2_{ij}\delta^2_{ij} $$

$\delta^2_{ij}$ is an indicator function (1 if obs$i$ and $j$ are from the same cluster, 0 otherwise). $SS_A$ Then difference between the overall and the within groups sum-of-squares ($SS_{A}=SS_{T}-SS_{W}$).

$$ F = \frac{\frac{SS_{A}}{p-1}}{\frac{SS_{W}}{N-p}} $$

## New metric

The idea of the new metric is: what if we represent the heterogeneity of a cluster by its maximum distance. Therefore, the average maximum distance within tends to decrease as the number of cluster increases.

In counterpart, let's think the min distance between clusters as how different two clusters are. Thus, the average minimum distance between clusters also tends to decrease as the number of clusters increase.

Lets call this metric $T$.

$$T = \frac{\frac{1}{k}\sum_{(i,j)\in k}\max(d(x_i,x_j))}
{\frac{1}{k}\sum_{(i,j)\notin k}\min(d(x_i,x_j))}$$
:::

# Creating the clusters

```{r}
running=T

if(running){
  ## pure biotic factors = 
  list_with_clusters_alpha0 <- clusterize_ward_pam(
    distMatrix = inducedDist_$normalizedAitDist,
    maxnclust = 50,
    dFrameAsv = dframe$ASV_composition$name)
  
  alpha_=0.1
  
  distMatrix_ = alpha_*inducedDist_$normalizedMyDist+(1-alpha_)*inducedDist_$normalizedAitDist
  
  list_with_clusters_alpha0.10 <- clusterize_ward_pam(
    distMatrix = distMatrix_,
    maxnclust = 50,
    dFrameAsv = dframe$ASV_composition$name)

  alpha_=0.25
  
  distMatrix_ = alpha_*inducedDist_$normalizedMyDist+(1-alpha_)*inducedDist_$normalizedAitDist
  
  list_with_clusters_alpha0.25 <- clusterize_ward_pam(
    distMatrix = distMatrix_,
    maxnclust = 50,
    dFrameAsv = dframe$ASV_composition$name)
  
  alpha_=0.5
  
  distMatrix_ = alpha_*inducedDist_$normalizedMyDist+(1-alpha_)*inducedDist_$normalizedAitDist
  
  list_with_clusters_alpha0.50 <- clusterize_ward_pam(
    distMatrix = distMatrix_,
    maxnclust = 50,
    dFrameAsv = dframe$ASV_composition$name)
  
  saveRDS(object = list_with_clusters_alpha0,file = paste0(savingdir,'/','list_with_clusters_alpha0'))
  saveRDS(object = list_with_clusters_alpha0.10,file = paste0(savingdir,'/','list_with_clusters_alpha0.10'))
  saveRDS(object = list_with_clusters_alpha0.25,file = paste0(savingdir,'/','list_with_clusters_alpha0.25'))
  saveRDS(object = list_with_clusters_alpha0.50,file = paste0(savingdir,'/','list_with_clusters_alpha0.50'))
}

list_with_clusters_alpha0 = readRDS(file = paste0(savingdir,'/','list_with_clusters_alpha0'))
list_with_clusters_alpha0.10 = readRDS(file = paste0(savingdir,'/','list_with_clusters_alpha0.10'))
list_with_clusters_alpha0.25 = readRDS(file = paste0(savingdir,'/','list_with_clusters_alpha0.25'))
list_with_clusters_alpha0.50 = readRDS(file = paste0(savingdir,'/','list_with_clusters_alpha0.50'))
```

# Calculating Metrics

::: panel-tabset
## hclust

```{r}
running = F

if(running){
  nclusters <- ncol(list_with_clusters_alpha0$dFrameAsv_hclust)-1
  list_results <- list()
  
  for( i in 1:nclusters){
    list_results[[i]] <-  eval_adist_clustering(compositionDF = left_join(
      list_with_clusters_alpha0$dFrameAsv_hclust[,c(1,i+1)] %>% rename('name'=1,'Cluster'=2),
      dframe$ASV_composition))
    cat('iteration------:',i,'\n')
  }
  saveRDS(list_results,file = paste0(savingdir,'/','list_results_eval_alpha0_hclust'))
}

if(running){
  nclusters <- ncol(list_with_clusters_alpha0.10$dFrameAsv_hclust)-1
  list_results <- list()
  
  for( i in 1:nclusters){
    list_results[[i]] <-  eval_adist_clustering(compositionDF = left_join(
      list_with_clusters_alpha0.10$dFrameAsv_hclust[,c(1,i+1)] %>% rename('name'=1,'Cluster'=2),
      dframe$ASV_composition))
    cat('iteration------:',i,'\n')
  }
  saveRDS(list_results,file = paste0(savingdir,'/','list_results_eval_alpha0.10_hclust'))
}

if(running){
  nclusters <- ncol(list_with_clusters_alpha0.25$dFrameAsv_hclust)-1
  list_results <- list()
  
  for( i in 1:nclusters){
    list_results[[i]] <-  eval_adist_clustering(compositionDF = left_join(
      list_with_clusters_alpha0.25$dFrameAsv_hclust[,c(1,i+1)] %>% rename('name'=1,'Cluster'=2),
      dframe$ASV_composition))
    cat('iteration------:',i,'\n')
  }
  saveRDS(list_results,file = paste0(savingdir,'/','list_results_eval_alpha0.25_hclust'))
}

if(running){
  nclusters <- ncol(list_with_clusters_alpha0.50$dFrameAsv_hclust)-1
  list_results <- list()
  
  for( i in 1:nclusters){
    list_results[[i]] <-  eval_adist_clustering(compositionDF = left_join(
      list_with_clusters_alpha0.50$dFrameAsv_hclust[,c(1,i+1)] %>% rename('name'=1,'Cluster'=2),
      dframe$ASV_composition))
    cat('iteration------:',i,'\n')
  }
  saveRDS(list_results,file = paste0(savingdir,'/','list_results_eval_alpha0.50_hclust'))
}


# list_results_eval_alpha0_hclust = readRDS(paste0(savingdir,'/','list_results_eval_alpha0_hclust'))
# 
# summarise_adist_clustering(list_results_eval_alpha0_hclust) %>%
#   reshape2::melt(id.vars = "nclust") %>% 
#   filter(nclust > 1) %>% 
#   ggplot(aes(x = nclust, y = value, group = variable)) +
#     geom_line() +
#     theme_minimal(base_size = 12) +
#     facet_wrap(~variable, scales = "free_y")
```

## pam

```{r}
running =F

if(running){
  nclusters <- ncol(list_with_clusters_alpha0$dFrameAsv_pam)-1
  list_results <- list()
  
  for( i in 1:nclusters){
    list_results[[i]] <-  eval_adist_clustering(compositionDF = left_join(
      list_with_clusters_alpha0$dFrameAsv_pam[,c(1,i+1)] %>% rename('name'=1,'Cluster'=2),
      dframe$ASV_composition))
    cat('iteration------:',i,'\n')
  }
  saveRDS(list_results,file = paste0(savingdir,'/','list_results_eval_alpha0_pam'))
}

if(running){
  nclusters <- ncol(list_with_clusters_alpha0.10$dFrameAsv_pam)-1
  list_results <- list()
  
  for( i in 1:nclusters){
    list_results[[i]] <-  eval_adist_clustering(compositionDF = left_join(
      list_with_clusters_alpha0.10$dFrameAsv_pam[,c(1,i+1)] %>% rename('name'=1,'Cluster'=2),
      dframe$ASV_composition))
    cat('iteration------:',i,'\n')
  }
  saveRDS(list_results,file = paste0(savingdir,'/','list_results_eval_alpha0.10_pam'))
}

if(running){
  nclusters <- ncol(list_with_clusters_alpha0.25$dFrameAsv_pam)-1
  list_results <- list()
  
  for( i in 1:nclusters){
    list_results[[i]] <-  eval_adist_clustering(compositionDF = left_join(
      list_with_clusters_alpha0.25$dFrameAsv_pam[,c(1,i+1)] %>% rename('name'=1,'Cluster'=2),
      dframe$ASV_composition))
    cat('iteration------:',i,'\n')
  }
  saveRDS(list_results,file = paste0(savingdir,'/','list_results_eval_alpha0.25_pam'))
}

if(running){
  nclusters <- ncol(list_with_clusters_alpha0.50$dFrameAsv_pam)-1
  list_results <- list()
  
  for( i in 1:nclusters){
    list_results[[i]] <-  eval_adist_clustering(compositionDF = left_join(
      list_with_clusters_alpha0.50$dFrameAsv_pam[,c(1,i+1)] %>% rename('name'=1,'Cluster'=2),
      dframe$ASV_composition))
    cat('iteration------:',i,'\n')
  }
  saveRDS(list_results,file = paste0(savingdir,'/','list_results_eval_alpha0.50_pam'))
}

# list_results_eval_alpha0_pam = readRDS(paste0(savingdir,'/','list_results_eval_alpha0_pam'))
# 
# summarise_adist_clustering(list_results_eval_alpha0_pam) %>%
#   reshape2::melt(id.vars = "nclust") %>% 
#   filter(nclust > 1) %>% 
#   ggplot(aes(x = nclust, y = value, group = variable)) +
#     geom_line() +
#     theme_minimal(base_size = 12) +
#     facet_wrap(~variable, scales = "free_y")
```
:::

# Splitting and Evaluating Metrics

::: panel-tabset
## Calculating

Here you will only find the scripts to generate the results

```{r}
############# -- arranging data

############# Finding K -------------------------------------------------------------------
running = F
if (running){
  set.seed(1234)
  alpha0_bootstrap = finding_optimal_k_parallel(
    dframe_asv = dframe$dframe %>% select(SampleKey,ASV_name,Raw.Sequence.Counts),
    B = 500,split_pct = 0.5,maxnclust_ = 50,vec_functions_fromEnv = funcitons_parallel)
  saveRDS(alpha0_bootstrap,file = paste0(savingdir,'/','alpha0_bootstrap'))
}

running = F
if (running){
  set.seed(1234)
  alpha0_bootstrap = finding_optimal_k_parallel(
    dframe_asv = dframe$dframe %>% select(SampleKey,ASV_name,Raw.Sequence.Counts),
    B = 500,split_pct = 0.5,maxnclust_ = 50,vec_functions_fromEnv = funcitons_parallel,
    inducedDistMatrix = inducedDist_$normalizedMyDist,alpha_ = 0.10)
  saveRDS(alpha0_bootstrap,file = paste0(savingdir,'/','alpha0.10_bootstrap'))
}


running = F
if (running){
  set.seed(1234)
  alpha0_bootstrap = finding_optimal_k_parallel(
    dframe_asv = dframe$dframe %>% select(SampleKey,ASV_name,Raw.Sequence.Counts),
    B = 500,split_pct = 0.5,maxnclust_ = 50,vec_functions_fromEnv = funcitons_parallel,
    inducedDistMatrix = inducedDist_$normalizedMyDist,alpha_ = 0.25)
  saveRDS(alpha0_bootstrap,file = paste0(savingdir,'/','alpha0.25_bootstrap'))
}

running = F
if (running){
  set.seed(1234)
  alpha0_bootstrap = finding_optimal_k_parallel(
    dframe_asv = dframe$dframe %>% select(SampleKey,ASV_name,Raw.Sequence.Counts),
    B = 500,split_pct = 0.5,maxnclust_ = 50,vec_functions_fromEnv = funcitons_parallel,
    inducedDistMatrix = inducedDist_$normalizedMyDist,alpha_ = 0.50)
  saveRDS(alpha0_bootstrap,file = paste0(savingdir,'/','alpha0.50_bootstrap'))
}
############# Finding K -------------------------------------------------------------------
```

```{r}
############# Permanova -------------------------------------------------------------------
running = F
if(running){
perm_alpha0 = permanova_custom(
  list_with_clusters = list_with_clusters_alpha0,
  ait_distMatrix = inducedDist_$normalizedAitDist,
  B = 500)
saveRDS(perm_alpha0,file = paste0(savingdir,'/','perm_alpha0'))
}

running = F
if(running){
perm_alpha0.10 = permanova_custom(
  list_with_clusters = list_with_clusters_alpha0.10,
  ait_distMatrix = inducedDist_$normalizedAitDist,
  B = 500)
saveRDS(perm_alpha0.10,file = paste0(savingdir,'/','perm_alpha0.10'))
}

running = F
if(running){
perm_alpha0.25 = permanova_custom(
  list_with_clusters = list_with_clusters_alpha0.25,
  ait_distMatrix = inducedDist_$normalizedAitDist,
  B = 500)
saveRDS(perm_alpha0.25,file = paste0(savingdir,'/','perm_alpha0.25'))
}

running = F
if(running){
perm_alpha0.50 = permanova_custom(
  list_with_clusters = list_with_clusters_alpha0.50,
  ait_distMatrix = inducedDist_$normalizedAitDist,
  B = 500)
saveRDS(perm_alpha0.50,file = paste0(savingdir,'/','perm_alpha0.50'))
}

```

```{r}
## arranging the results

############# Finding K -------------------------------------------------------------------
alpha0_cv = readRDS(paste0(savingdir,'/','alpha0_bootstrap'))
alpha0_cv_df = data.table::rbindlist(alpha0_cv) %>% data.frame()


############# Permanova -------------------------------------------------------------------
perm_alpha <- readRDS(paste0(savingdir,'/','perm_alpha0'))

df_permanova <- plyr::ldply(perm_alpha$hclust, function(el){
  return(data.frame(nclust = el$nclust[1], pvalue = el$`Pr(>F)`[1], r2 = el$R2[1]))
}, .id = "nclust")

df_permanova2 <- plyr::ldply(perm_alpha$pam, function(el){
  return(data.frame(nclust = el$nclust[1], pvalue = el$`Pr(>F)`[1], r2 = el$R2[1]))
}, .id = "nclust")


df_perm_alpha0 = bind_rows(
  df_permanova %>% mutate(method='hclust'),
  df_permanova2 %>% mutate(method='pam'),
) %>% mutate(alpha=0)

########### 0.1 

perm_alpha <- readRDS(paste0(savingdir,'/','perm_alpha0.10'))

df_permanova <- plyr::ldply(perm_alpha$hclust, function(el){
  return(data.frame(nclust = el$nclust[1], pvalue = el$`Pr(>F)`[1], r2 = el$R2[1]))
}, .id = "nclust")

df_permanova2 <- plyr::ldply(perm_alpha$pam, function(el){
  return(data.frame(nclust = el$nclust[1], pvalue = el$`Pr(>F)`[1], r2 = el$R2[1]))
}, .id = "nclust")


df_perm_alpha0.10 = bind_rows(
  df_permanova %>% mutate(method='hclust'),
  df_permanova2 %>% mutate(method='pam'),
) %>% mutate(alpha=0.10)

########### 0.25
perm_alpha <- readRDS(paste0(savingdir,'/','perm_alpha0.25'))

df_permanova <- plyr::ldply(perm_alpha$hclust, function(el){
  return(data.frame(nclust = el$nclust[1], pvalue = el$`Pr(>F)`[1], r2 = el$R2[1]))
}, .id = "nclust")

df_permanova2 <- plyr::ldply(perm_alpha$pam, function(el){
  return(data.frame(nclust = el$nclust[1], pvalue = el$`Pr(>F)`[1], r2 = el$R2[1]))
}, .id = "nclust")

df_perm_alpha0.25 = bind_rows(
  df_permanova %>% mutate(method='hclust'),
  df_permanova2 %>% mutate(method='pam'),
) %>% mutate(alpha=0.25)

########### 0.50
perm_alpha <- readRDS(paste0(savingdir,'/','perm_alpha0.50'))

df_permanova <- plyr::ldply(perm_alpha$hclust, function(el){
  return(data.frame(nclust = el$nclust[1], pvalue = el$`Pr(>F)`[1], r2 = el$R2[1]))
}, .id = "nclust")

df_permanova2 <- plyr::ldply(perm_alpha$pam, function(el){
  return(data.frame(nclust = el$nclust[1], pvalue = el$`Pr(>F)`[1], r2 = el$R2[1]))
}, .id = "nclust")

df_perm_alpha0.50 = bind_rows(
  df_permanova %>% mutate(method='hclust'),
  df_permanova2 %>% mutate(method='pam'),
) %>% mutate(alpha=0.50)


df_perm  = bind_rows(df_perm_alpha0,df_perm_alpha0.10,df_perm_alpha0.25,df_perm_alpha0.50)
```

## Results

::: panel-tabset
### Proposed Metrics

'CV-like' measurement was calculated at 500 iterations of:

1.  After the split

    -   create the composition of ASVs in 50% of the samples
    -   fit the clustering methods (hclust and pam) from k = 1 : 50
    -   evaluate each cluster in the 'test' data

```{r}
# alpha0_cv_df %>% 
#   reshape2::melt(id.vars = c("nclust","method","iteration") ) %>%
#   filter(nclust > 1) %>% 
#   select(-iteration) %>% select(variable) %>% distinct() %>% pull()

group_summary = c('ratio_avg_within_between','ratio_avg_max_min')

group_permanova = c('Fstat','SSA','SSW')
group_S = c('ratio_avg_within_between','mean_avg_within','avg_between_medoids')

group_max = c('max_max_dist_within','avg_max_dist_within','max_min_dist_clust_i_other',
              'avg_min_dist_clust_i_other')
```


```{r}
#| fig-width: 12
#| fig-height: 6

alpha0_cv_df %>% 
  reshape2::melt(id.vars = c("nclust","method","iteration") ) %>%
  filter(nclust > 1) %>% 
  select(-iteration) %>% 
  filter(variable %in% group_summary) %>% 
  group_by(method,nclust,variable) %>% 
  summarise(avg=mean(value),stdev=sd(value)) %>% 
  ungroup() %>% 
  ggplot(aes(x = nclust, y = avg, group = method,
             color=method,fill=method)) +
  geom_line() +
  geom_ribbon(aes(ymin=avg-stdev, ymax=avg+stdev),alpha=0.5)+
  theme_minimal(base_size = 16) +
  facet_wrap(~variable, scales = "free_y")+
  theme(legend.position = 'bottom')
```

```{r}
#| fig-width: 12
#| fig-height: 5
alpha0_cv_df %>% 
  reshape2::melt(id.vars = c("nclust","method","iteration") ) %>%
  filter(nclust > 1) %>% 
  select(-iteration) %>% 
  filter(variable %in% group_permanova) %>% 
  group_by(method,nclust,variable) %>% 
  summarise(avg=mean(value),stdev=sd(value)) %>% 
  ungroup() %>% 
  ggplot(aes(x = nclust, y = avg, group = method,
             color=method,fill=method)) +
  geom_line() +
  geom_ribbon(aes(ymin=avg-stdev, ymax=avg+stdev),alpha=0.5)+
  theme_minimal(base_size = 16) +
  facet_wrap(~variable, scales = "free_y")+
  theme(legend.position = 'bottom')
```

```{r}
#| fig-width: 12
#| fig-height: 5
alpha0_cv_df %>% 
  reshape2::melt(id.vars = c("nclust","method","iteration") ) %>%
  filter(nclust > 1) %>% 
  select(-iteration) %>% 
  filter(variable %in% group_S) %>% 
  group_by(method,nclust,variable) %>% 
  summarise(avg=mean(value),stdev=sd(value)) %>% 
  ungroup() %>% 
  ggplot(aes(x = nclust, y = avg, group = method,
             color=method,fill=method)) +
  geom_line() +
  geom_ribbon(aes(ymin=avg-stdev, ymax=avg+stdev),alpha=0.5)+
  theme_minimal(base_size = 16) +
  facet_wrap(~variable, scales = "free_y")+
  theme(legend.position = 'bottom')
```

```{r}
#| fig-width: 12
#| fig-height: 8
alpha0_cv_df %>% 
  reshape2::melt(id.vars = c("nclust","method","iteration") ) %>%
  filter(nclust > 1) %>% 
  select(-iteration) %>% 
  filter(variable %in% group_max) %>% 
  group_by(method,nclust,variable) %>% 
  summarise(avg=mean(value),stdev=sd(value)) %>% 
  ungroup() %>% 
  ggplot(aes(x = nclust, y = avg, group = method,
             color=method,fill=method)) +
  geom_line() +
  geom_ribbon(aes(ymin=avg-stdev, ymax=avg+stdev),alpha=0.5)+
  theme_minimal(base_size = 16) +
  facet_wrap(~variable, scales = "free_y")+
  theme(legend.position = 'bottom')
```

```{r}
alpha0_cv_df %>% 
  reshape2::melt(id.vars = c("nclust","method","iteration") ) %>%
  filter(nclust > 1) %>% 
  select(-iteration) %>% 
  #mutate(nclust=factor(nclust,levels=1:number_clusters)) %>% 
  group_by(method,nclust,variable) %>% 
  #summarise(avg=mean(value),stdev=sd(value)) %>% 
  #ungroup() %>% 
  #group_by(method,nclust,variable) %>% 
  summarise(Freq_Problem = sum(is.infinite(value))) %>% 
  filter(Freq_Problem>0) %>% 
  knitr::kable() %>% kableExtra::kable_styling()
```

```{r}
alpha0_cv_df %>% 
  reshape2::melt(id.vars = c("nclust","method","iteration") ) %>%
  filter(nclust > 1) %>% 
  select(-iteration) %>% 
  #mutate(nclust=factor(nclust,levels=1:number_clusters)) %>% 
  group_by(method,nclust,variable) %>% 
  #summarise(avg=mean(value),stdev=sd(value)) %>% 
  #ungroup() %>% 
  #group_by(method,nclust,variable) %>% 
  summarise(Freq_Problem = sum(is.infinite(value))) %>% 
  filter(Freq_Problem>0) %>% 
  knitr::kable() %>% kableExtra::kable_styling()
```

```{r}
alpha0_cv_df %>% 
  reshape2::melt(id.vars = c("nclust","method","iteration") ) %>%
  filter(nclust > 1) %>% 
  select(-iteration) %>% 
  #mutate(nclust=factor(nclust,levels=1:number_clusters)) %>% 
  group_by(method,nclust,variable) %>% 
  #summarise(avg=mean(value),stdev=sd(value)) %>% 
  #ungroup() %>% 
  #group_by(method,nclust,variable) %>% 
  summarise(Freq_Problem = sum(value==0)) %>% 
  filter(Freq_Problem>0) %>% 
  knitr::kable() %>% kableExtra::kable_styling()
```

```{r}
alpha0_cv_df %>% 
  reshape2::melt(id.vars = c("nclust","method","iteration") ) %>%
  filter(nclust > 1) %>% 
  select(-iteration) %>% 
  #mutate(nclust=factor(nclust,levels=1:number_clusters)) %>% 
  group_by(method,nclust,variable) %>% 
  summarise(avg=mean(value),stdev=sd(value)) %>% 
  ungroup() %>% 
  ggplot(aes(x = nclust, y = avg, group = method,color=method,fill=method)) +
    geom_line() +
    geom_ribbon(aes(ymin=avg-stdev, ymax=avg+stdev),alpha=0.5)+
    theme_minimal(base_size = 12) +
    facet_wrap(~variable, scales = "free_y")+
  theme(legend.position = 'bottom')
```

### Permanova

```{r}
#| fig-width: 12
#| fig-height: 6
df_perm %>% filter(nclust>1) %>% 
  mutate(alpha_=factor(alpha)) %>% 
  ggplot(aes(
  x=nclust,y=r2,color=method,linetype=alpha_
  ))+
  geom_line()+
  theme_minimal()+
  theme(legend.position = 'bottom')
```
:::
:::

# Consistency Metric

::: panel-tabset

## Calculating
```{r}
######## --- stable with alpha = 0 
######## --- here is the script if you want to run it parallellized
######## --- the caviat is that it uses too much memory - needs better implementation
running=F 
if(running){
  stable_obj_alpha0 <- asv_stable_calc(
    dframe_asv=dframe$dframe %>% select(SampleKey,ASV_name,Raw.Sequence.Counts),
    B=500,
    split_pct = 0.5,
    nclust=10,
    vec_functions_fromEnv=funcitons_parallel,
    splittingInducerMatrix=NULL
  )
}

######## --- stable with alpha = 0.1
if(running){
  stable_obj_alpha0.10 <- asv_stable_calc(
    dframe_asv=dframe$dframe %>% select(SampleKey,ASV_name,Raw.Sequence.Counts),
    B=500,
    split_pct = 0.5,
    nclust=10,
    vec_functions_fromEnv=funcitons_parallel,
    splittingInducerMatrix=inducedDist_$normalizedMyDist,alpha_ = 0.1)
  saveRDS(object = stable_obj_alpha0.10,
          file = paste0(savingdir,'/','stable_obj_alpha0.10'))
}

######## --- stable with alpha = 0.25
if(running){
  stable_obj_alpha0.25 <- asv_stable_calc(
    dframe_asv=dframe$dframe %>% select(SampleKey,ASV_name,Raw.Sequence.Counts),
    B=500,
    split_pct = 0.5,
    nclust=10,
    vec_functions_fromEnv=funcitons_parallel,
    splittingInducerMatrix=inducedDist_$normalizedMyDist,alpha_ = 0.25)
  saveRDS(object = stable_obj_alpha0.25,
          file = paste0(savingdir,'/','stable_obj_alpha0.25'))
}

######## --- here is the script for running it not parellized
running=F 
if(running){
  stable_obj_alpha0 <- asv_stable_calc_notparallel(
    dframe_asv=dframe$dframe %>% select(SampleKey,ASV_name,Raw.Sequence.Counts),
    B=500,
    split_pct = 0.5,
    nclust=10,
    splittingInducerMatrix=NULL
  )
}

######## --- stable with alpha = 0.1
if(running){
  stable_obj_alpha0.10 <- asv_stable_calc_notparallel(
    dframe_asv=dframe$dframe %>% select(SampleKey,ASV_name,Raw.Sequence.Counts),
    B=500,
    split_pct = 0.5,
    nclust=10,
    splittingInducerMatrix=inducedDist_$normalizedMyDist,alpha_ = 0.1)
  saveRDS(object = stable_obj_alpha0.10,
          file = paste0(savingdir,'/','stable_obj_alpha0.10'))
}

######## --- stable with alpha = 0.25
if(running){
  stable_obj_alpha0.25 <- asv_stable_calc_notparallel(
    dframe_asv=dframe$dframe %>% select(SampleKey,ASV_name,Raw.Sequence.Counts),
    B=500,
    split_pct = 0.5,
    nclust=10,
    splittingInducerMatrix=inducedDist_$normalizedMyDist,alpha_ = 0.25)
  saveRDS(object = stable_obj_alpha0.25,
          file = paste0(savingdir,'/','stable_obj_alpha0.25'))
}

######
stable_obj_alpha0= readRDS(paste0(savingdir,'/','stable_obj_alpha0'))
stable_obj_alpha0.10= readRDS(paste0(savingdir,'/','stable_obj_alpha0.10'))
stable_obj_alpha0.25= readRDS(paste0(savingdir,'/','stable_obj_alpha0.25'))
```

## Results

::: panel-tabset

### Hclust

::: panel-tabset

#### All ASVs

```{r}
#| fig-width: 15
#| fig-height: 5
#| layout-ncol: 3

# pallete10 <- colorRampPalette(c('white','purple'))(10)
# #pallete10 = c("#FFFFFF",pallete10)
# 
# hclus_0 <- stable_obj_alpha0$hclust_#[1:250,1:250]
# hclus_0.10 <- stable_obj_alpha0.10$hclust_#[1:250,1:250]
# hclus_0.25 <- stable_obj_alpha0.25$hclust_#[1:250,1:250]
# 
# length(custom_breaks)
# length(labels_cut)
# 
# 
# dm = ggdendroplot::hmReady(df = hclus_0) %>% mutate(simm=cut(value,ordered_result = T,
#                   breaks = seq(0,1,0.1),include.lowest = T,right = T))
# 
# dm2 = ggdendroplot::hmReady(df = hclus_0.10) %>% mutate(simm=cut(value,ordered_result = T,
#                   breaks = seq(0,1,0.1),include.lowest = T,right = T))
# 
# dm3 = ggdendroplot::hmReady(df = hclus_0.25) %>% mutate(simm=cut(value,ordered_result = T,
#                   breaks = seq(0,1,0.1),include.lowest = T,right = T))
# 
# 
# dm %>% ggplot(aes(x=rowid, y=variable, fill=simm)) + 
#   geom_tile() + 
#   theme_minimal() +
#   theme(
#     axis.text.x = element_blank(),
#     axis.text.y = element_blank(),
#     axis.ticks = element_blank())+
#   scale_fill_manual(values = pallete10)
# 
# dm2 %>% ggplot(aes(x=rowid, y=variable, fill=simm)) + 
#   geom_tile() + 
#   theme_minimal() +
#   theme(
#     axis.text.x = element_blank(),
#     axis.text.y = element_blank(),
#     axis.ticks = element_blank())+
#   scale_fill_manual(values = pallete10)
# 
# dm3 %>% ggplot(aes(x=rowid, y=variable, fill=simm)) + 
#   geom_tile() + 
#   theme_minimal() +
#   theme(
#     axis.text.x = element_blank(),
#     axis.text.y = element_blank(),
#     axis.ticks = element_blank())+
#   scale_fill_manual(values = pallete10)
```


```{r}
#| fig-width: 15
#| fig-height: 3
#| layout-ncol: 3
# p1 = dm %>%
#   group_by(simm) %>% 
#   summarise(Pct = n()/nrow(dm)) %>%
#   ggplot(aes(x=simm,y=Pct))+
#   geom_col()+
#   theme_minimal()
#   
# p2 = dm2 %>%
#   group_by(simm) %>% 
#   summarise(Pct = n()/nrow(dm)) %>%
#   ggplot(aes(x=simm,y=Pct))+
#   geom_col()+
#   theme_minimal()
# 
# p3 = dm3 %>%
#   group_by(simm) %>% 
#   summarise(Pct = n()/nrow(dm)) %>%
#   ggplot(aes(x=simm,y=Pct))+
#   geom_col()+
#   theme_minimal()
# 
# gridExtra::grid.arrange(p1,p2,p3,ncol=3)
```

Let's reorder to get a better visualization.

```{r}
# asv_names_ <- rownames(hclus_0)
# hclus_0_cut_obj <- hclust(d=as.dist(1-hclus_0),method = 'ward.D')
# #plot(hclus_0_cut_obj,labels = F)
# hclus_0_cut = data.frame(
#   asv_names = asv_names_,
#   clusterCluster = cutree(hclus_0_cut_obj,k = 11))
# 
# hclus_0_cut = hclus_0_cut %>% arrange(clusterCluster)
# order_asv2 <- hclus_0_cut$asv_names
# 
# dm = ggdendroplot::hmReady(df = hclus_0) %>%
#   mutate(simm=cut(value,ordered_result = T,breaks = seq(0,1,0.1),include.lowest = T,right = F)) %>% 
#   mutate(rowid=factor(rowid,labels =order_asv2),
#          variable=factor(variable,labels = order_asv2)) %>% 
#   arrange(rowid,variable)
# 
# dm2 = ggdendroplot::hmReady(df = hclus_0.10) %>% mutate(simm=cut(value,ordered_result = T,
#                   breaks = seq(0,1,0.1),include.lowest = T,right = F))
# 
# dm3 = ggdendroplot::hmReady(df = hclus_0.25) %>% mutate(simm=cut(value,ordered_result = T,
#                   breaks = seq(0,1,0.1),include.lowest = T,right = F))
# 
# dm %>% ggplot(aes(x=rowid, y=variable, fill=simm)) + 
#   geom_tile() + 
#   theme_minimal() +
#   theme(
#     axis.text.x = element_blank(),
#     axis.text.y = element_blank(),
#     axis.ticks = element_blank())+
#   scale_fill_manual(values = pallete10)
# 
# dm2 %>% ggplot(aes(x=rowid, y=variable, fill=simm)) + 
#   geom_tile() + 
#   theme_minimal() +
#   theme(
#     axis.text.x = element_blank(),
#     axis.text.y = element_blank(),
#     axis.ticks = element_blank())+
#   scale_fill_manual(values = pallete10)
# 
# dm3 %>% ggplot(aes(x=rowid, y=variable, fill=simm)) + 
#   geom_tile() + 
#   theme_minimal() +
#   theme(
#     axis.text.x = element_blank(),
#     axis.text.y = element_blank(),
#     axis.ticks = element_blank())+
#   scale_fill_manual(values = pallete10)

### only this one worked!
# hm_0 <- heatmap.2(x = hclus_0,trace='none',
#                 col = colorRampPalette(c('white','orange','darkblue'))(10),
#                 breaks = seq(0,1,length.out=11),dendrogram = 'none')

```

#### Labeled vs Labeled
```{r}
# df_asv_species = dframe$ASV_composition %>% transmute(ASV_name=name) %>% 
#   left_join(dframe$dframe %>% select(ASV_name,Species) %>% distinct()) %>% 
#   filter(!is.na(Species)) %>% 
#   arrange(Species)
# 
# asv_glob <- df_asv_species %>% filter(Species=='Phaeocystis_globosa') %>% select(ASV_name) %>% pull()
# asv_pouchetii <- df_asv_species %>% filter(Species=='Phaeocystis_pouchetii') %>% select(ASV_name) %>% pull()
# asv_rex <- df_asv_species %>% filter(Species=='Phaeocystis_rex') %>% select(ASV_name) %>% pull()
# asv_cordata <- df_asv_species %>% filter(Species=='Phaeocystis_cordata') %>% select(ASV_name) %>% pull()
# asv_antarctica <- df_asv_species %>% filter(Species=='Phaeocystis_antarctica') %>% select(ASV_name) %>% pull()
# 
# df_asv_species$ASV_name
# 
# df_test <- dm2 %>% filter(rowid%in%df_asv_species$ASV_name,
#               variable%in%df_asv_species$ASV_name)
# df_test$rowid <- factor(df_test$rowid, levels = df_asv_species$ASV_name, ordered = T)
# df_test$variable <- factor(df_test$variable, levels = df_asv_species$ASV_name, ordered = T)
# df_test %>% 
#   #left_join(df_asv_species %>% rename('rowid'=1,'species1'=2)) %>% 
#   #left_join(df_asv_species %>% rename('variable'=1,'species2'=2)) %>% 
#   #arrange(species1,species2) %>% 
#   #mutate(rowid=factor(rowid,ordered = T,labels = df_asv_species$ASV_name),
#   #       variable=factor(variable,ordered = T,labels = df_asv_species$ASV_name)) %>% 
#   ggplot(aes(x=rowid, y=variable, fill=simm)) + 
#   geom_tile() + 
#   theme_minimal() +
#   # theme(
#   #   axis.text.x = element_blank(),
#   #   axis.text.y = element_blank(),
#   #   axis.ticks = element_blank())+
#   scale_fill_manual(values = pallete10)
# 
# 
# 
```


#### Labeled vs unlabeled

:::

### pam
::: panel-tabset

#### All ASVs

```{r}
#| fig-width: 15
#| fig-height: 5
#| layout-ncol: 3

# pallete10 <- colorRampPalette(c('white','purple'))(10)
# #pallete10 = c("#FFFFFF",pallete10)
# 
# hclus_0 <- stable_obj_alpha0$pam_#[1:250,1:250]
# hclus_0.10 <- stable_obj_alpha0.10$pam_#[1:250,1:250]
# hclus_0.25 <- stable_obj_alpha0.25$pam_#[1:250,1:250]
# 
# dm = ggdendroplot::hmReady(df = hclus_0) %>% mutate(simm=cut(value,ordered_result = T,
#                   breaks = seq(0,1,0.1),include.lowest = T,right = T))
# 
# dm2 = ggdendroplot::hmReady(df = hclus_0.10) %>% mutate(simm=cut(value,ordered_result = T,
#                   breaks = seq(0,1,0.1),include.lowest = T,right = T))
# 
# dm3 = ggdendroplot::hmReady(df = hclus_0.25) %>% mutate(simm=cut(value,ordered_result = T,
#                   breaks = seq(0,1,0.1),include.lowest = T,right = T))
# 
# 
# dm %>% ggplot(aes(x=rowid, y=variable, fill=simm)) + 
#   geom_tile() + 
#   theme_minimal() +
#   theme(
#     axis.text.x = element_blank(),
#     axis.text.y = element_blank(),
#     axis.ticks = element_blank())+
#   scale_fill_manual(values = pallete10)
# 
# dm2 %>% ggplot(aes(x=rowid, y=variable, fill=simm)) + 
#   geom_tile() + 
#   theme_minimal() +
#   theme(
#     axis.text.x = element_blank(),
#     axis.text.y = element_blank(),
#     axis.ticks = element_blank())+
#   scale_fill_manual(values = pallete10)
# 
# dm3 %>% ggplot(aes(x=rowid, y=variable, fill=simm)) + 
#   geom_tile() + 
#   theme_minimal() +
#   theme(
#     axis.text.x = element_blank(),
#     axis.text.y = element_blank(),
#     axis.ticks = element_blank())+
#   scale_fill_manual(values = pallete10)
```


```{r}
#| fig-width: 15
#| fig-height: 3
#| layout-ncol: 3
p1 = dm %>%
  group_by(simm) %>% 
  summarise(Pct = n()/nrow(dm)) %>%
  ggplot(aes(x=simm,y=Pct))+
  geom_col()+
  theme_minimal()
  
p2 = dm2 %>%
  group_by(simm) %>% 
  summarise(Pct = n()/nrow(dm)) %>%
  ggplot(aes(x=simm,y=Pct))+
  geom_col()+
  theme_minimal()

p3 = dm3 %>%
  group_by(simm) %>% 
  summarise(Pct = n()/nrow(dm)) %>%
  ggplot(aes(x=simm,y=Pct))+
  geom_col()+
  theme_minimal()

gridExtra::grid.arrange(p1,p2,p3,ncol=3)
```

Let's reorder to get a better visualization.

```{r}
#.  asv_names_ <- rownames(hclus_0)
#.  hclus_0_cut_obj <- hclust(d=as.dist(1-hclus_0),method = 'ward.D')
#.  #plot(hclus_0_cut_obj,labels = F)
#.  hclus_0_cut = data.frame(
#.    asv_names = asv_names_,
#.    clusterCluster = cutree(hclus_0_cut_obj,k = 11))
#.  
#.  hclus_0_cut = hclus_0_cut %>% arrange(clusterCluster)
#.  order_asv2 <- hclus_0_cut$asv_names
#.  
#.  dm = ggdendroplot::hmReady(df = hclus_0) %>%
#.    mutate(simm=cut(value,ordered_result = T,breaks = seq(0,1,0.1),include.lowest = T,right = F)) %>% 
#.    mutate(rowid=factor(rowid,labels =order_asv2),
#.           variable=factor(variable,labels = order_asv2)) %>% 
#.    arrange(rowid,variable)
#.  
#.  dm2 = ggdendroplot::hmReady(df = hclus_0.10) %>% mutate(simm=cut(value,ordered_result = T,
#.                    breaks = seq(0,1,0.1),include.lowest = T,right = F))
#.  
#.  dm3 = ggdendroplot::hmReady(df = hclus_0.25) %>% mutate(simm=cut(value,ordered_result = T,
#.                    breaks = seq(0,1,0.1),include.lowest = T,right = F))
#.  
#.  dm %>% ggplot(aes(x=rowid, y=variable, fill=simm)) + 
#.    geom_tile() + 
#.    theme_minimal() +
#.    theme(
#.      axis.text.x = element_blank(),
#.      axis.text.y = element_blank(),
#.      axis.ticks = element_blank())+
#.    scale_fill_manual(values = pallete10)
#.  
#.  dm2 %>% ggplot(aes(x=rowid, y=variable, fill=simm)) + 
#.    geom_tile() + 
#.    theme_minimal() +
#.    theme(
#.      axis.text.x = element_blank(),
#.      axis.text.y = element_blank(),
#.      axis.ticks = element_blank())+
#.    scale_fill_manual(values = pallete10)
#.  
#.  dm3 %>% ggplot(aes(x=rowid, y=variable, fill=simm)) + 
#.    geom_tile() + 
#.    theme_minimal() +
#.    theme(
#.      axis.text.x = element_blank(),
#.      axis.text.y = element_blank(),
#.      axis.ticks = element_blank())+
#.    scale_fill_manual(values = pallete10)
#.  
#.  ### only this one worked!
#.  # hm_0 <- heatmap.2(x = hclus_0,trace='none',
#.  #                 col = colorRampPalette(c('white','orange','darkblue'))(10),
#.  #                 breaks = seq(0,1,length.out=11),dendrogram = 'none')
#.  
```

#### Labeled vs Labeled
```{r}
# df_asv_species = dframe$ASV_composition %>% transmute(ASV_name=name) %>% 
#   left_join(dframe$dframe %>% select(ASV_name,Species) %>% distinct()) %>% 
#   filter(!is.na(Species)) %>% 
#   arrange(Species)
# 
# asv_glob <- df_asv_species %>% filter(Species=='Phaeocystis_globosa') %>% select(ASV_name) %>% pull()
# asv_pouchetii <- df_asv_species %>% filter(Species=='Phaeocystis_pouchetii') %>% select(ASV_name) %>% pull()
# asv_rex <- df_asv_species %>% filter(Species=='Phaeocystis_rex') %>% select(ASV_name) %>% pull()
# asv_cordata <- df_asv_species %>% filter(Species=='Phaeocystis_cordata') %>% select(ASV_name) %>% pull()
# asv_antarctica <- df_asv_species %>% filter(Species=='Phaeocystis_antarctica') %>% select(ASV_name) %>% pull()
# 
# df_asv_species$ASV_name
# 
# df_test <- dm3 %>% filter(rowid%in%df_asv_species$ASV_name,
#               variable%in%df_asv_species$ASV_name)
# df_test$rowid <- factor(df_test$rowid, levels = df_asv_species$ASV_name, ordered = T)
# df_test$variable <- factor(df_test$variable, levels = df_asv_species$ASV_name, ordered = T)
# df_test %>% 
#   #left_join(df_asv_species %>% rename('rowid'=1,'species1'=2)) %>% 
#   #left_join(df_asv_species %>% rename('variable'=1,'species2'=2)) %>% 
#   #arrange(species1,species2) %>% 
#   #mutate(rowid=factor(rowid,ordered = T,labels = df_asv_species$ASV_name),
#   #       variable=factor(variable,ordered = T,labels = df_asv_species$ASV_name)) %>% 
#   ggplot(aes(x=rowid, y=variable, fill=simm)) + 
#   geom_tile() + 
#   theme_minimal() +
#   # theme(
#   #   axis.text.x = element_blank(),
#   #   axis.text.y = element_blank(),
#   #   axis.ticks = element_blank())+
#   scale_fill_manual(values = pallete10)
# 
# 
# 
```


#### Labeled vs unlabeled

:::

:::

:::

# Plots and others 



```{r}
alpha_ = 0.5
combdist=  alpha_*inducedDist_$normalizedMyDist + (1-alpha_)*inducedDist_$normalizedAitDist
pam_10 = cluster::pam(x = as.dist(combdist),k = 15)

df_clusters = data.frame(
  ASV_name=dframe$ASV_composition$name,
  Cluster = pam_10$clustering)

asvGroupping <- AnalyzeASVgroup(
  dfLonger = dframe$dframe %>% 
    left_join(df_clusters),
  clusterVar = 'Cluster',
  sampleVar = 'SampleID')
```

::: panel-tabset
##### ASV vs Species

Comparing the Species and The groupping that we got:

```{r}
asvGroupping$barplot
```

```{r}
asvGroupping$RelativeFreq
```

```{r}
asvGroupping$Freq
```

##### Most abundant ASV in each sample

```{r}
asvGroupping$MostAbundantFreq %>% knitr::kable() %>% kableExtra::kable_styling()
```

```{r}
asvGroupping$mapView
```

##### ASV groups vs Longhurst - Based on RA

Here, the denominator is the sum of the `raw.sequence.counts` for each longhurst, and than observe the RA of each ASVG inside each longhurst

```{r}
asvGroupping$BarPlot_ASVG_LH_RA
```

Here, the denominator is the sum of the `raw.sequence.counts` for each ASVG, and than observe the RA of each longhurst inside each ASVG

```{r}
asvGroupping$BarPlot_ASVG_LH_RA2
```

##### Spatial - Most Abundant ASVG

Each sample here is represented by it's most abundant ASV Group.

```{r}
asvGroupping$LatDepth
```

```{r}
asvGroupping$LatLong
```

```{r}
asvGroupping$DepthLong
```

##### Spatial

If the ASV Groupping is not present, than the point is removed.

```{r}
asvGroupping$LatDepth_stacked
```

```{r}
asvGroupping$LatLong_stacked
```

```{r}
asvGroupping$DepthLong_stacked
```

##### Abiotic Factors

Just to remember the percentage of the data that has missing on the abiotic factors

```{r}
asvGroupping$MissingAbiotic
```

I'm just plotting the samples for which we have information.

Univariate

```{r}
#| fig-height: 12
asvGroupping$MatrixAbioticsUnivar
```

Bivariate

```{r}
#| fig-height: 16
#| fig-width: 16
asvGroupping$MatrixAbioticsBiVar
```

<!--Sub Sub Sec 2 -  Close -->
:::

:::
