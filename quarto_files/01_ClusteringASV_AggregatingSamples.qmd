---
title: "Clustering ASVs"
format: 
  html:
    fig-width: 12
    fig-height: 8
    fig-align: center
    echo: true
    code-fold: true
    fig-dpi: 100
    warning: false
    message: false
    page-layout: custom
    embed-resources: true
---

::: panel-tabset
# Data Handling

```{r}
library(dplyr) ; library(tidyr) ; library(ggplot2) 
library(doParallel) ; library(foreach) ; library(doSNOW)

root <- rprojroot::has_file(".git/index")
datadir = root$find_file("data")
funsdir = root$find_file("functions")
savingdir = root$find_file("saved_files")

datapath = root$find_file(paste0(datadir,'/','grump.phaeocystis_asv_long.csv'))
files_vec <- list.files(funsdir)
currentwd <- getwd()

for( i in 1:length(files_vec)){
  source(root$find_file(paste0(funsdir,'/',files_vec[i])))
}

funcitons_parallel = c("clusterize_ward_pam",
                       "eval_adist_clustering",
                       "inducedDist",
                       "summarise_adist_clustering",
                       "tidy_grump")

dframe = data.table::fread(input = datapath)
dframe_allASVs = tidy_grump(Dframe = dframe)
```

# splitting inducer distance matrix

The idea is to create a 'custom' distance matrix, to induce the grouppings.

-   $c_1$ is within the same species - but no unassigned
-   $c_2$ is between assigned species
-   $c_3$ is between species and unassigned
-   $c_4$ is within unassigned and unassigned

![](InduceddistMatrix.png){width="25%" fig-align="center"}

For this document we will use only the following configuration:

$c_1=1$, $c_2=1000$, $c_3=10$ , $c_4=10$

A priori, the 'probability\` of unassigned ASVs to agglomerate between themselves is the same as if it was to agglomerate with other species. Large $c_2$ makes it harder for known species ASVs to group between themselves.

```{r}
inducedDist_ = inducedDist(
  dFrame = dframe_allASVs$dframe,
  c1 = 1,c2=1000,c3=10,c4=10,
  compMatrix = dframe_allASVs$ASV_composition)
#inducedDist$myDist_checking
```

# Excluding zeros

If we exclude the ASVs that appears only one ~or two~ times, does it help?

```{r}
nASVs <- dframe_allASVs$dframe %>% select(ASV_name) %>% distinct() %>% nrow()

plot0s_summ = dframe_allASVs$dframe %>% group_by(ASV_name,SampleKey) %>% 
  summarise(Freq=n()) %>%
  mutate(nSamplesObserved = sum(Freq)) %>% 
  arrange(nSamplesObserved) %>% 
  select(ASV_name,nSamplesObserved) %>% distinct() %>%
  mutate(FreqNSamples=cut(nSamplesObserved,breaks = c(0,1,2,3,5,10,25,50,100,250,1500),right = T,include.lowest = T)) %>% 
  group_by(FreqNSamples) %>% 
  summarise(Freq=n(),Pct=n()/nASVs) %>% 
  mutate(CummPct = cumsum(Pct))
  

plot0s_summ %>% ggplot(aes(x=FreqNSamples,y=Freq))+geom_bar(stat='identity')
plot0s_summ %>% ggplot(aes(x=FreqNSamples,y=CummPct))+geom_bar(stat='identity')

plot0s_summ %>% knitr::kable() %>% kableExtra::kable_styling()


### Creating vectors with id of ASVs to remove:
ASVs2Remove_df = dframe_allASVs$dframe %>% group_by(ASV_name,SampleKey) %>% 
  summarise(Freq=n()) %>%
  mutate(nSamplesObserved = sum(Freq)) %>% 
  arrange(nSamplesObserved) %>% 
  select(ASV_name,nSamplesObserved) %>% distinct() 

vetASVs_2orMore = ASVs2Remove_df %>% filter(nSamplesObserved>1) %>% select(ASV_name) %>% pull()
vetASVs_3orMore = ASVs2Remove_df %>% filter(nSamplesObserved>2) %>% select(ASV_name) %>% pull()
```
This is the number of ASVs that are preset in exactly that amount of samples.

Lets look now the number of samples with how many ASVs,

```{r}
## now looking ASVs inside samples
plot0s_summ2 = dframe_allASVs$dframe %>% 
  group_by(SampleKey) %>% 
  summarise(Freq=n()) %>% 
  arrange(Freq) %>% 
  mutate(FreqAsvs=cut(Freq,breaks = c(0,1,2,3,5,10,25,50,100,250),
                      right = T,include.lowest = T)) %>% 
  group_by(FreqAsvs) %>% 
  summarise(Freq=n(),Pct=n()/nSamples) %>% 
  mutate(CummPct = cumsum(Pct))

plot0s_summ2 %>% knitr::kable() %>% kableExtra::kable_styling()

```


Lets now compare the distance matrix using mds, ltns, and umap.

::: panel-tabset
## All Asvs
```{r}
dim_reduce_obj <- dim_reduce_plots(dfComposition = dframe_allASVs$ASV_composition)
```

## Two or More
```{r}
dframe2plus = tidy_grump(Dframe = dframe,vet_ASVs2remove = vetASVs_2orMore)
dim_reduce_obj2plus <- dim_reduce_plots(
  dfComposition = dframe2plus$ASV_composition,perplexityTsne = 100)

dim_reduce_obj2plus$MDS2d_ASVs_Ait
dim_reduce_obj2plus$TSNE_ASVs_Ait_2d
dim_reduce_obj2plus$umap_ASVs_Ait_2d
```

## Three or More
```{r}
dframe3plus = tidy_grump(Dframe = dframe,vet_ASVs2remove = vetASVs_3orMore)
dim_reduce_obj3plus <- dim_reduce_plots(dframe3plus = dframe2plus$ASV_composition)
```

:::

# Aggregating samples

Here the idea is to aggregate some samples. So we would have compositions of ASVs but instead of samples we would have a less sparse and with less dimensions. The most natural could be:

1.  Compositions of ASVs, under longhurst provinces
2.  Compositions of ASVs, under longhurst provinces combined with different depths
3.  Cruises?
4.  Chunks of latitudes, and chunks of depths.

So for each aggregation we should take a look at mds, tsne, umap of the ait distances (or distance matrix using the CLR transformation)

So first lets do a bit of EDA to see what we can expect.


```{r}
dframe$dframe %>% select(SampleKey,Depth,Longhurst_Short) %>% distinct() %>% 
  ggplot(aes(Depth))+geom_histogram()+
  facet_wrap(~Longhurst_Short)




dframe$dframe  %>% select()
      group_by(Longhurst_Short,ASV_name) %>% 
      mutate(Raw.Sequence.Counts = sum(Raw.Sequence.Counts)) %>% 


      pivot_wider(id_cols = Longhurst_Short_,
                  values_from ='Raw.Sequence.Counts',
                  names_from='ASV_name',values_fill = 0) %>%
      arrange(SampleKey) %>% 
      mutate(across(where(is.numeric))/
               rowSums(across(where(is.numeric)))) %>% ### Here we have the compositions on the samples
      mutate(across(where(is.numeric),function(x) {x+0.00000000001}))%>%  ### Adding a small value in all, in order to have the CLR transformation / aitichison distance
      mutate(across(where(is.numeric))/rowSums(across(where(is.numeric)))) %>% ### composition over the samples gain
      pivot_longer(cols = any_of(idAsvs)) %>% ## Stacking to transpose 
      pivot_wider(id_cols='name',
                  values_from = value,
                  names_from='SampleKey') %>% ## Wider again, ASVs in the row
      mutate(across(where(is.numeric))/rowSums(across(where(is.numeric)))) %>% # each row is an ASVs and the columns are the sample. The rows now add to 1.
      arrange(name) %>% data.frame()




```











:::